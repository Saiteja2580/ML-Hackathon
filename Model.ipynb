{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load input data\n",
    "X = pd.read_csv('data/train/X_Train_Data_Input.csv')\n",
    "\n",
    "# Load target data\n",
    "Y = pd.read_csv('data/train/Y_Train_Data_Target.csv')\n",
    "\n",
    "# Display the first few rows to verify the contents\n",
    "X.head()\n",
    "Y.head()\n",
    "\n",
    "\n",
    "x = X.iloc[:,1:]\n",
    "y = Y.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()\n",
    "print(\"No.of rows : \",x.shape[0])\n",
    "print(\"No.of Columns : \",x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking each row is aligned correctly with corresponding id\n",
    "are_ids_aligned = X['ID'].equals(Y['ID'])\n",
    "if are_ids_aligned:\n",
    "    print(x.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = x.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "percent = (x.isnull().sum()/x.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "null_percent_table = pd.concat([total,percent],axis=1,keys=['Total','Percent'])\n",
    "\n",
    "null_percent_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying imputation to generate values for null values using the algorithms Using LightGBM\n",
    "xdata = x.copy()\n",
    "xdata.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#importing lightGBM imputation function to impute the missing values\n",
    "import algorithm_scripts.null_imputation as nm\n",
    "xdata_imputed = nm.lightgbm_impute(xdata)\n",
    "print(xdata_imputed.isnull().sum())\n",
    "\n",
    "xdata_imputed.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_imputed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyzing or visualizing feature distribution\n",
    "xdata_imputed.hist(bins=30,figsize=(25,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.boxplot(data=xdata_imputed)\n",
    "plt.title('Box Plot for Outlier Detection')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkig the outliers\n",
    "from algorithm_scripts.outlier_detection import IQR\n",
    "\n",
    "outliers = IQR(xdata_imputed)\n",
    "outliers.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from algorithm_scripts.outlier_detection import iqrImpute\n",
    "imputed_data = iqrImpute(xdata_imputed)\n",
    "imputed_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.boxplot(data=imputed_data)\n",
    "plt.title('Box Plot for Outlier Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_imputed = imputed_data\n",
    "xdata_imputed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing correlation analysis \n",
    "corr_marix = xdata_imputed.corr()\n",
    "plt.figure(figsize=(25,15))\n",
    "sns.heatmap(corr_marix,annot=True,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now checking for balancing or imbalancinfg the dataset\n",
    "class_distribution = y.value_counts()\n",
    "class_distribution\n",
    "from algorithm_scripts.balancing_dataset import smote\n",
    "\n",
    "balanced_data = smote(xdata_imputed,y)\n",
    "x_balanced = balanced_data[0]\n",
    "y_balanced = balanced_data[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata_imputed = iqrImpute(x_balanced)\n",
    "y = y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xdata_imputed.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.svm import train_svm_model\n",
    "\n",
    "accuracy = train_svm_model(xdata_imputed,y=y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
